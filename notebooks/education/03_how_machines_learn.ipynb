{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“˜ Module 3: æœºå™¨å¦‚ä½•å­¦ä¹ ï¼Ÿ- æ•°æ®é©±åŠ¨æ¨¡å‹å…¥é—¨ (How Machines Learn)\n",
    "\n",
    "## å­¦ä¹ ç›®æ ‡ (Learning Objectives)\n",
    "\n",
    "- ç†è§£LSTMå¦‚ä½•å¤„ç†æ—¶åºæ•°æ®\n",
    "- å¯¹æ¯”ç‰©ç†æ¨¡å‹å’Œæ•°æ®é©±åŠ¨æ¨¡å‹çš„å·®å¼‚\n",
    "- é€šè¿‡å¯è§†åŒ–ç†è§£è®­ç»ƒè¿‡ç¨‹\n",
    "- è®¤è¯†è¿‡æ‹Ÿåˆä¸æ³›åŒ–èƒ½åŠ›çš„é‡è¦æ€§\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¤– ä»€ä¹ˆæ˜¯æ•°æ®é©±åŠ¨æ¨¡å‹ï¼Ÿ\n",
    "\n",
    "åœ¨å‰ä¸¤ä¸ªæ¨¡å—ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†**ç‰©ç†æ¨¡å‹**ï¼ˆå¦‚HBVï¼‰ï¼Œå®ƒä½¿ç”¨å…¬å¼æ¥æè¿°æ°´æ–‡è¿‡ç¨‹ã€‚\n",
    "\n",
    "ç°åœ¨ï¼Œè®©æˆ‘ä»¬è®¤è¯†å¦ä¸€ç§å®Œå…¨ä¸åŒçš„æ–¹æ³•ï¼š**æ•°æ®é©±åŠ¨æ¨¡å‹**ã€‚\n",
    "\n",
    "### ä¸€ä¸ªæœ‰è¶£çš„ç±»æ¯”\n",
    "\n",
    "æƒ³è±¡æœ‰ä¸¤ç§å­¦ç”Ÿåœ¨å­¦ä¹ é¢„æµ‹æ²³æµæµé‡ï¼š\n",
    "\n",
    "| | ç‰©ç†æ¨¡å‹å­¦ç”Ÿ | æ•°æ®é©±åŠ¨æ¨¡å‹å­¦ç”Ÿ |\n",
    "|---|-------------|----------------|\n",
    "| å­¦ä¹ æ–¹å¼ | èƒŒå…¬å¼ã€ç†è§£åŸç† | å¤§é‡åšé¢˜ã€æ‰¾è§„å¾‹ |\n",
    "| éœ€è¦çš„çŸ¥è¯† | æ°´æ–‡å­¦ç†è®º | å†å²æ•°æ® |\n",
    "| é¢å¯¹æ–°é—®é¢˜ | åº”ç”¨å…¬å¼ | ç±»æ¯”ä»¥å‰çš„é¢˜ç›® |\n",
    "| ä¼˜åŠ¿ | èƒ½è§£é‡Šä¸ºä»€ä¹ˆ | å¯èƒ½æ›´å‡†ç¡® |\n",
    "| åŠ£åŠ¿ | å…¬å¼å¯èƒ½ä¸å®Œç¾ | å¯èƒ½\"æ­»è®°ç¡¬èƒŒ\" |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®ç»˜å›¾å‚æ•°\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# æ£€æŸ¥GPUå¯ç”¨æ€§\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"âœ… ç¯å¢ƒè®¾ç½®å®Œæˆï¼\")\n",
    "print(f\"ğŸ“Ÿ ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯é‡å¤\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§  Part 1: è®¤è¯†LSTM\n",
    "\n",
    "### ä»€ä¹ˆæ˜¯LSTMï¼Ÿ\n",
    "\n",
    "**LSTM (Long Short-Term Memory)** æ˜¯ä¸€ç§ç‰¹æ®Šçš„å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰ï¼Œ\n",
    "å®ƒæœ‰ä¸€ä¸ª\"è®°å¿†\"æœºåˆ¶ï¼Œèƒ½å¤Ÿå­¦ä¹ æ—¶é—´åºåˆ—æ•°æ®ä¸­çš„é•¿æœŸä¾èµ–å…³ç³»ã€‚\n",
    "\n",
    "### ä¸ºä»€ä¹ˆLSTMé€‚åˆæ°´æ–‡å»ºæ¨¡ï¼Ÿ\n",
    "\n",
    "æƒ³æƒ³æ²³æµçš„æµé‡ï¼š\n",
    "- ä»Šå¤©çš„æµé‡ä¸ä»…å–å†³äºä»Šå¤©çš„é™é›¨\n",
    "- è¿˜å–å†³äºè¿‡å»å‡ å¤©ç”šè‡³å‡ å‘¨çš„é™é›¨ï¼ˆåœŸå£¤æ°´åˆ†ã€åœ°ä¸‹æ°´ç­‰ï¼‰\n",
    "- LSTMå¯ä»¥\"è®°ä½\"è¿™äº›å†å²ä¿¡æ¯ï¼\n",
    "\n",
    "### LSTMçš„\"è®°å¿†\"æœºåˆ¶\n",
    "\n",
    "LSTMæœ‰ä¸‰ä¸ª\"é—¨\"æ¥æ§åˆ¶ä¿¡æ¯æµï¼š\n",
    "1. **é—å¿˜é—¨ (Forget Gate)** â†’ å†³å®šä¸¢å¼ƒå“ªäº›æ—§ä¿¡æ¯ï¼ˆç±»ä¼¼äºè’¸å‘ã€ä¸‹æ¸—ï¼‰\n",
    "2. **è¾“å…¥é—¨ (Input Gate)** â†’ å†³å®šä¿ç•™å“ªäº›æ–°ä¿¡æ¯ï¼ˆç±»ä¼¼äºé™é›¨è¡¥ç»™ï¼‰\n",
    "3. **è¾“å‡ºé—¨ (Output Gate)** â†’ å†³å®šè¾“å‡ºä»€ä¹ˆï¼ˆç±»ä¼¼äºäº§ç”Ÿå¾„æµï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_lstm_gates():\n",
    "    \"\"\"\n",
    "    å¯è§†åŒ–LSTMçš„é—¨æœºåˆ¶ä¸æ°´æ–‡è¿‡ç¨‹çš„ç±»æ¯”\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # å·¦å›¾ï¼šLSTMç»“æ„\n",
    "    ax1 = axes[0]\n",
    "    ax1.set_xlim(0, 10)\n",
    "    ax1.set_ylim(0, 10)\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title('LSTM é—¨ç»“æ„', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # ç”»LSTMå•å…ƒ\n",
    "    from matplotlib.patches import Rectangle, FancyArrowPatch, Circle\n",
    "    \n",
    "    # ä¸»ä½“\n",
    "    cell = Rectangle((2, 3), 6, 4, fill=True, facecolor='lightblue', \n",
    "                      edgecolor='black', linewidth=2)\n",
    "    ax1.add_patch(cell)\n",
    "    ax1.text(5, 5, 'Cell State\\n(è®°å¿†)', fontsize=12, ha='center', va='center')\n",
    "    \n",
    "    # é—¨\n",
    "    gates = [\n",
    "        (3, 2.5, 'Forget\\né—å¿˜é—¨', 'red'),\n",
    "        (5, 2.5, 'Input\\nè¾“å…¥é—¨', 'green'),\n",
    "        (7, 2.5, 'Output\\nè¾“å‡ºé—¨', 'blue'),\n",
    "    ]\n",
    "    \n",
    "    for x, y, label, color in gates:\n",
    "        gate = Circle((x, y), 0.5, fill=True, facecolor=color, alpha=0.5)\n",
    "        ax1.add_patch(gate)\n",
    "        ax1.text(x, y-1.2, label, fontsize=9, ha='center')\n",
    "    \n",
    "    # ç®­å¤´\n",
    "    ax1.annotate('', xy=(5, 8), xytext=(5, 7), \n",
    "                arrowprops=dict(arrowstyle='->', lw=2))\n",
    "    ax1.text(5, 8.3, 'ä¸Šä¸€ä¸ªè®°å¿†', fontsize=10, ha='center')\n",
    "    \n",
    "    ax1.annotate('', xy=(1, 5), xytext=(2, 5),\n",
    "                arrowprops=dict(arrowstyle='<-', lw=2))\n",
    "    ax1.text(0.5, 5, 'è¾“å…¥', fontsize=10, ha='center')\n",
    "    \n",
    "    ax1.annotate('', xy=(9, 5), xytext=(8, 5),\n",
    "                arrowprops=dict(arrowstyle='->', lw=2))\n",
    "    ax1.text(9.5, 5, 'è¾“å‡º', fontsize=10, ha='center')\n",
    "    \n",
    "    # å³å›¾ï¼šæ°´æ–‡ç±»æ¯”\n",
    "    ax2 = axes[1]\n",
    "    ax2.set_xlim(0, 10)\n",
    "    ax2.set_ylim(0, 10)\n",
    "    ax2.axis('off')\n",
    "    ax2.set_title('æ°´æ–‡è¿‡ç¨‹ç±»æ¯”', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # æ°´ç®±\n",
    "    tank = Rectangle((3, 2), 4, 5, fill=True, facecolor='lightcyan',\n",
    "                     edgecolor='blue', linewidth=2)\n",
    "    ax2.add_patch(tank)\n",
    "    ax2.text(5, 4.5, 'æµåŸŸå‚¨æ°´\\n(åœŸå£¤+åœ°ä¸‹æ°´)', fontsize=11, ha='center', va='center')\n",
    "    \n",
    "    # è¾“å…¥ç®­å¤´ï¼ˆé™é›¨ï¼‰\n",
    "    ax2.annotate('', xy=(5, 7.5), xytext=(5, 9),\n",
    "                arrowprops=dict(arrowstyle='->', lw=2, color='blue'))\n",
    "    ax2.text(5, 9.3, 'é™é›¨ (Input)', fontsize=10, ha='center', color='blue')\n",
    "    \n",
    "    # è’¸å‘ç®­å¤´\n",
    "    ax2.annotate('', xy=(7.5, 8), xytext=(6.5, 6.5),\n",
    "                arrowprops=dict(arrowstyle='->', lw=2, color='red'))\n",
    "    ax2.text(8, 8.2, 'è’¸å‘\\n(Forget)', fontsize=9, ha='center', color='red')\n",
    "    \n",
    "    # å‡ºæµç®­å¤´\n",
    "    ax2.annotate('', xy=(5, 0.5), xytext=(5, 2),\n",
    "                arrowprops=dict(arrowstyle='->', lw=2, color='green'))\n",
    "    ax2.text(5, 0, 'å¾„æµ (Output)', fontsize=10, ha='center', color='green')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_lstm_gates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Part 2: å‡†å¤‡æ•°æ®\n",
    "\n",
    "åœ¨è®­ç»ƒLSTMä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å°†æ•°æ®ç»„ç»‡æˆç‰¹å®šçš„æ ¼å¼ï¼š\n",
    "- **è¾“å…¥ (X)**: è¿‡å»nå¤©çš„æ°”è±¡æ•°æ®ï¼ˆé™æ°´ã€æ¸©åº¦ã€PETï¼‰\n",
    "- **è¾“å‡º (Y)**: å½“å¤©çš„å¾„æµ\n",
    "\n",
    "è¿™å«åš**æ»‘åŠ¨çª—å£ (Sliding Window)** æ–¹æ³•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(n_days=1000):\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆåˆæˆçš„æ°”è±¡-å¾„æµæ•°æ®\n",
    "    \n",
    "    æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€åŒ–çš„ç‰©ç†å…³ç³»æ¥ç”Ÿæˆ\"çœŸå®\"æ•°æ®ï¼Œ\n",
    "    ç„¶åè®©LSTMæ¥å­¦ä¹ è¿™ä¸ªå…³ç³»ã€‚\n",
    "    \"\"\"\n",
    "    # æ°”è±¡æ•°æ®\n",
    "    day_of_year = np.arange(n_days) % 365\n",
    "    \n",
    "    # æ¸©åº¦ï¼šå­£èŠ‚æ€§ + éšæœºæ³¢åŠ¨\n",
    "    temp = 15 + 10 * np.sin(2 * np.pi * (day_of_year - 91) / 365)\n",
    "    temp += np.random.normal(0, 3, n_days)\n",
    "    \n",
    "    # é™æ°´ï¼šéšæœºäº‹ä»¶\n",
    "    precip = np.zeros(n_days)\n",
    "    rain_prob = 0.3 + 0.1 * np.sin(2 * np.pi * day_of_year / 365)  # å­£èŠ‚æ€§å˜åŒ–\n",
    "    for i in range(n_days):\n",
    "        if np.random.random() < rain_prob[i]:\n",
    "            precip[i] = np.random.exponential(scale=10)\n",
    "    \n",
    "    # PETï¼šä¸æ¸©åº¦ç›¸å…³\n",
    "    pet = np.maximum(0, 0.5 + 0.2 * temp + np.random.normal(0, 0.5, n_days))\n",
    "    \n",
    "    # ç”Ÿæˆ\"çœŸå®\"å¾„æµï¼ˆä½¿ç”¨ç®€åŒ–çš„æ°´ç®±æ¨¡å‹ï¼‰\n",
    "    discharge = np.zeros(n_days)\n",
    "    storage = 100  # åˆå§‹å‚¨æ°´\n",
    "    \n",
    "    for t in range(n_days):\n",
    "        # é™æ°´è¾“å…¥\n",
    "        storage += precip[t] * 0.7  # 70%çš„é™æ°´å½¢æˆæœ‰æ•ˆè¡¥ç»™\n",
    "        \n",
    "        # è’¸å‘æŸå¤±\n",
    "        evap = min(pet[t] * 0.8, storage * 0.05)\n",
    "        storage -= evap\n",
    "        \n",
    "        # éçº¿æ€§å‡ºæµ\n",
    "        discharge[t] = 0.1 * storage + 0.05 * max(0, storage - 150)\n",
    "        storage -= discharge[t]\n",
    "        storage = max(0, storage)\n",
    "    \n",
    "    # æ·»åŠ ä¸€äº›è§‚æµ‹å™ªå£°\n",
    "    discharge += np.random.normal(0, 0.5, n_days)\n",
    "    discharge = np.maximum(0, discharge)\n",
    "    \n",
    "    return precip, temp, pet, discharge\n",
    "\n",
    "# ç”Ÿæˆæ•°æ®\n",
    "precip, temp, pet, discharge = generate_synthetic_data(1000)\n",
    "\n",
    "print(f\"ğŸ“Š æ•°æ®ç”Ÿæˆå®Œæˆï¼\")\n",
    "print(f\"   æ ·æœ¬æ•°: {len(precip)} å¤©\")\n",
    "print(f\"   é™æ°´å‡å€¼: {precip.mean():.2f} mm/day\")\n",
    "print(f\"   å¾„æµå‡å€¼: {discharge.mean():.2f} mm/day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(precip, temp, pet, discharge, seq_length=30):\n",
    "    \"\"\"\n",
    "    åˆ›å»ºè®­ç»ƒåºåˆ—\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    seq_length : int\n",
    "        ä½¿ç”¨è¿‡å»å¤šå°‘å¤©çš„æ•°æ®æ¥é¢„æµ‹å½“å¤©å¾„æµ\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    X : np.ndarray, shape (n_samples, seq_length, n_features)\n",
    "    y : np.ndarray, shape (n_samples,)\n",
    "    \"\"\"\n",
    "    # å †å ç‰¹å¾\n",
    "    features = np.stack([precip, temp, pet], axis=1)  # (n_days, 3)\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(seq_length, len(features)):\n",
    "        # è¿‡å»seq_lengthå¤©çš„ç‰¹å¾\n",
    "        X.append(features[i-seq_length:i])\n",
    "        # å½“å¤©çš„å¾„æµ\n",
    "        y.append(discharge[i])\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# åˆ›å»ºåºåˆ—\n",
    "SEQ_LENGTH = 30  # ä½¿ç”¨è¿‡å»30å¤©çš„æ•°æ®\n",
    "X, y = create_sequences(precip, temp, pet, discharge, seq_length=SEQ_LENGTH)\n",
    "\n",
    "print(f\"\\nğŸ“ æ•°æ®å½¢çŠ¶:\")\n",
    "print(f\"   X shape: {X.shape} - (æ ·æœ¬æ•°, åºåˆ—é•¿åº¦, ç‰¹å¾æ•°)\")\n",
    "print(f\"   y shape: {y.shape} - (æ ·æœ¬æ•°,)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ä¸€ä¸ªæ ·æœ¬\n",
    "def visualize_sample(X, y, sample_idx=100):\n",
    "    \"\"\"\n",
    "    å¯è§†åŒ–ä¸€ä¸ªè®­ç»ƒæ ·æœ¬\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(12, 10), sharex=True)\n",
    "    \n",
    "    sample = X[sample_idx]  # (seq_length, 3)\n",
    "    target = y[sample_idx]\n",
    "    \n",
    "    days = np.arange(SEQ_LENGTH)\n",
    "    \n",
    "    # é™æ°´\n",
    "    axes[0].bar(days, sample[:, 0], color='steelblue', alpha=0.7)\n",
    "    axes[0].set_ylabel('Precip [mm]')\n",
    "    axes[0].set_title(f'æ ·æœ¬ #{sample_idx} - è¾“å…¥ç‰¹å¾ (è¿‡å»{SEQ_LENGTH}å¤©)', fontweight='bold')\n",
    "    \n",
    "    # æ¸©åº¦\n",
    "    axes[1].plot(days, sample[:, 1], 'r-', linewidth=2)\n",
    "    axes[1].set_ylabel('Temp [Â°C]')\n",
    "    \n",
    "    # PET\n",
    "    axes[2].plot(days, sample[:, 2], 'g-', linewidth=2)\n",
    "    axes[2].set_ylabel('PET [mm]')\n",
    "    \n",
    "    # ç›®æ ‡\n",
    "    axes[3].axhline(y=target, color='coral', linewidth=3, label=f'Target Q = {target:.2f} mm')\n",
    "    axes[3].set_ylabel('Discharge [mm]')\n",
    "    axes[3].set_xlabel('Days in Lookback Window')\n",
    "    axes[3].set_title('ç›®æ ‡ - å½“å¤©å¾„æµ', fontweight='bold')\n",
    "    axes[3].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_sample(X, y, sample_idx=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ Part 3: æ„å»ºLSTMæ¨¡å‹\n",
    "\n",
    "ç°åœ¨è®©æˆ‘ä»¬ç”¨PyTorchæ„å»ºä¸€ä¸ªç®€å•çš„LSTMæ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    ç®€å•çš„LSTMæ°´æ–‡æ¨¡å‹\n",
    "    \n",
    "    ç»“æ„ï¼š\n",
    "    è¾“å…¥ -> LSTMå±‚ -> å…¨è¿æ¥å±‚ -> è¾“å‡º\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=3, hidden_size=32, num_layers=1, dropout=0.0):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTMå±‚\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # å…¨è¿æ¥è¾“å‡ºå±‚\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        å‰å‘ä¼ æ’­\n",
    "        \n",
    "        x: (batch_size, seq_length, input_size)\n",
    "        \"\"\"\n",
    "        # LSTMå±‚\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        \n",
    "        # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "        \n",
    "        # å…¨è¿æ¥å±‚\n",
    "        output = self.fc(last_output)\n",
    "        \n",
    "        return output.squeeze(-1)\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹\n",
    "model = SimpleLSTM(input_size=3, hidden_size=32, num_layers=1)\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"ğŸ—ï¸ æ¨¡å‹ç»“æ„:\")\n",
    "print(model)\n",
    "print(f\"\\nğŸ“Š å‚æ•°æ€»æ•°: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Part 4: è®­ç»ƒæ¨¡å‹ - è§‚å¯Ÿå­¦ä¹ è¿‡ç¨‹\n",
    "\n",
    "ç°åœ¨æ˜¯æœ€æ¿€åŠ¨äººå¿ƒçš„éƒ¨åˆ† - çœ‹çœ‹æ¨¡å‹å¦‚ä½•ä»æ•°æ®ä¸­\"å­¦ä¹ \"ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‡†å¤‡æ•°æ®\n",
    "# åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "train_size = int(len(X) * 0.7)\n",
    "\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# æ ‡å‡†åŒ–\n",
    "X_mean, X_std = X_train.mean(axis=(0,1)), X_train.std(axis=(0,1))\n",
    "y_mean, y_std = y_train.mean(), y_train.std()\n",
    "\n",
    "X_train_norm = (X_train - X_mean) / (X_std + 1e-8)\n",
    "X_test_norm = (X_test - X_mean) / (X_std + 1e-8)\n",
    "y_train_norm = (y_train - y_mean) / (y_std + 1e-8)\n",
    "y_test_norm = (y_test - y_mean) / (y_std + 1e-8)\n",
    "\n",
    "# è½¬æ¢ä¸ºPyTorchå¼ é‡\n",
    "X_train_t = torch.FloatTensor(X_train_norm).to(device)\n",
    "X_test_t = torch.FloatTensor(X_test_norm).to(device)\n",
    "y_train_t = torch.FloatTensor(y_train_norm).to(device)\n",
    "y_test_t = torch.FloatTensor(y_test_norm).to(device)\n",
    "\n",
    "# åˆ›å»ºDataLoader\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"ğŸ“Š æ•°æ®åˆ’åˆ†:\")\n",
    "print(f\"   è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬\")\n",
    "print(f\"   æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, X_test_t, y_test_t, epochs=50, lr=0.01):\n",
    "    \"\"\"\n",
    "    è®­ç»ƒæ¨¡å‹å¹¶è®°å½•è¿‡ç¨‹\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    train_losses : è®­ç»ƒæŸå¤±å†å²\n",
    "    test_losses : æµ‹è¯•æŸå¤±å†å²\n",
    "    predictions_history : æ¯10ä¸ªepochçš„é¢„æµ‹ç»“æœ\n",
    "    \"\"\"\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    predictions_history = {}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # è®­ç»ƒæ¨¡å¼\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = epoch_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # è¯„ä¼°æ¨¡å¼\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_pred = model(X_test_t)\n",
    "            test_loss = criterion(test_pred, y_test_t).item()\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            # ä¿å­˜ä¸€äº›epochçš„é¢„æµ‹ç»“æœ\n",
    "            if epoch in [0, 5, 10, 20, 49]:\n",
    "                predictions_history[epoch] = test_pred.cpu().numpy()\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1:3d}/{epochs} | Train Loss: {avg_train_loss:.4f} | Test Loss: {test_loss:.4f}\")\n",
    "    \n",
    "    return train_losses, test_losses, predictions_history\n",
    "\n",
    "# é‡æ–°åˆå§‹åŒ–æ¨¡å‹\n",
    "model = SimpleLSTM(input_size=3, hidden_size=32, num_layers=1).to(device)\n",
    "\n",
    "print(\"ğŸš€ å¼€å§‹è®­ç»ƒ...\\n\")\n",
    "train_losses, test_losses, pred_history = train_model(\n",
    "    model, train_loader, X_test_t, y_test_t, epochs=50, lr=0.01\n",
    ")\n",
    "print(\"\\nâœ… è®­ç»ƒå®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# å·¦å›¾ï¼šæŸå¤±æ›²çº¿\n",
    "epochs_range = np.arange(1, len(train_losses) + 1)\n",
    "axes[0].plot(epochs_range, train_losses, 'b-', linewidth=2, label='Train Loss')\n",
    "axes[0].plot(epochs_range, test_losses, 'r-', linewidth=2, label='Test Loss')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss (MSE)', fontsize=12)\n",
    "axes[0].set_title('è®­ç»ƒè¿‡ç¨‹ï¼šæŸå¤±ä¸‹é™', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# å³å›¾ï¼šé¢„æµ‹æ•ˆæœæ¼”å˜\n",
    "colors = plt.cm.viridis(np.linspace(0, 0.9, len(pred_history)))\n",
    "\n",
    "for (epoch, pred), color in zip(pred_history.items(), colors):\n",
    "    # åæ ‡å‡†åŒ–\n",
    "    pred_real = pred * y_std + y_mean\n",
    "    axes[1].plot(pred_real[:100], color=color, alpha=0.7, label=f'Epoch {epoch+1}')\n",
    "\n",
    "axes[1].plot(y_test[:100], 'k--', linewidth=2, label='Observed')\n",
    "axes[1].set_xlabel('Test Sample Index', fontsize=12)\n",
    "axes[1].set_ylabel('Discharge [mm/day]', fontsize=12)\n",
    "axes[1].set_title('é¢„æµ‹æ•ˆæœéšè®­ç»ƒè¿›åŒ–', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(loc='upper right')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('LSTMè®­ç»ƒå¯è§†åŒ–', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ è§‚å¯Ÿè¦ç‚¹\n",
    "\n",
    "1. **æŸå¤±ä¸‹é™**ï¼šéšç€è®­ç»ƒè¿›è¡Œï¼Œæ¨¡å‹çš„é¢„æµ‹è¯¯å·®é€æ¸å‡å°\n",
    "2. **ä»ä¹±ç”»åˆ°é€¼è¿‘**ï¼šåˆæœŸé¢„æµ‹å¾ˆå·®ï¼ŒåæœŸè¶Šæ¥è¶Šå‡†ç¡®\n",
    "3. **è®­ç»ƒvsæµ‹è¯•**ï¼šä¸¤æ¡æ›²çº¿çš„å·®è·åæ˜ äº†æ³›åŒ–èƒ½åŠ›"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš ï¸ Part 5: è¿‡æ‹Ÿåˆå®éªŒ - æ•°æ®é‡çš„é‡è¦æ€§\n",
    "\n",
    "ç°åœ¨è®©æˆ‘ä»¬åšä¸€ä¸ªå®éªŒï¼šå¦‚æœåªç”¨å¾ˆå°‘çš„æ•°æ®è®­ç»ƒï¼Œä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overfit_experiment(X, y, train_sizes=[10, 50, 100, 300, 500]):\n",
    "    \"\"\"\n",
    "    æ¼”ç¤ºä¸åŒæ•°æ®é‡ä¸‹çš„è¿‡æ‹Ÿåˆç°è±¡\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # å›ºå®šæµ‹è¯•é›†\n",
    "    X_test_exp = X[-200:]\n",
    "    y_test_exp = y[-200:]\n",
    "    \n",
    "    # æ ‡å‡†åŒ–ï¼ˆç”¨å…¨éƒ¨æ•°æ®çš„ç»Ÿè®¡é‡ï¼‰\n",
    "    X_mean_exp = X[:-200].mean(axis=(0,1))\n",
    "    X_std_exp = X[:-200].std(axis=(0,1))\n",
    "    y_mean_exp = y[:-200].mean()\n",
    "    y_std_exp = y[:-200].std()\n",
    "    \n",
    "    X_test_norm_exp = (X_test_exp - X_mean_exp) / (X_std_exp + 1e-8)\n",
    "    y_test_norm_exp = (y_test_exp - y_mean_exp) / (y_std_exp + 1e-8)\n",
    "    \n",
    "    X_test_t_exp = torch.FloatTensor(X_test_norm_exp).to(device)\n",
    "    y_test_t_exp = torch.FloatTensor(y_test_norm_exp).to(device)\n",
    "    \n",
    "    for train_size in train_sizes:\n",
    "        print(f\"\\nè®­ç»ƒæ•°æ®é‡: {train_size} å¤©\")\n",
    "        \n",
    "        # ä½¿ç”¨å‰train_sizeä¸ªæ ·æœ¬è®­ç»ƒ\n",
    "        X_train_exp = X[:train_size]\n",
    "        y_train_exp = y[:train_size]\n",
    "        \n",
    "        X_train_norm_exp = (X_train_exp - X_mean_exp) / (X_std_exp + 1e-8)\n",
    "        y_train_norm_exp = (y_train_exp - y_mean_exp) / (y_std_exp + 1e-8)\n",
    "        \n",
    "        X_train_t_exp = torch.FloatTensor(X_train_norm_exp).to(device)\n",
    "        y_train_t_exp = torch.FloatTensor(y_train_norm_exp).to(device)\n",
    "        \n",
    "        train_dataset_exp = TensorDataset(X_train_t_exp, y_train_t_exp)\n",
    "        batch_size_exp = min(32, train_size)\n",
    "        train_loader_exp = DataLoader(train_dataset_exp, batch_size=batch_size_exp, shuffle=True)\n",
    "        \n",
    "        # è®­ç»ƒæ–°æ¨¡å‹\n",
    "        model_exp = SimpleLSTM(input_size=3, hidden_size=32, num_layers=1).to(device)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model_exp.parameters(), lr=0.01)\n",
    "        \n",
    "        train_losses_exp = []\n",
    "        test_losses_exp = []\n",
    "        \n",
    "        for epoch in range(50):\n",
    "            model_exp.train()\n",
    "            for batch_X, batch_y in train_loader_exp:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model_exp(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            # è®°å½•æŸå¤±\n",
    "            model_exp.eval()\n",
    "            with torch.no_grad():\n",
    "                train_pred = model_exp(X_train_t_exp)\n",
    "                train_loss = criterion(train_pred, y_train_t_exp).item()\n",
    "                train_losses_exp.append(train_loss)\n",
    "                \n",
    "                test_pred = model_exp(X_test_t_exp)\n",
    "                test_loss = criterion(test_pred, y_test_t_exp).item()\n",
    "                test_losses_exp.append(test_loss)\n",
    "        \n",
    "        # æœ€ç»ˆé¢„æµ‹\n",
    "        model_exp.eval()\n",
    "        with torch.no_grad():\n",
    "            final_pred = model_exp(X_test_t_exp).cpu().numpy()\n",
    "            final_pred_real = final_pred * y_std_exp + y_mean_exp\n",
    "        \n",
    "        results[train_size] = {\n",
    "            'train_losses': train_losses_exp,\n",
    "            'test_losses': test_losses_exp,\n",
    "            'predictions': final_pred_real\n",
    "        }\n",
    "        \n",
    "        print(f\"  æœ€ç»ˆè®­ç»ƒæŸå¤±: {train_losses_exp[-1]:.4f}\")\n",
    "        print(f\"  æœ€ç»ˆæµ‹è¯•æŸå¤±: {test_losses_exp[-1]:.4f}\")\n",
    "    \n",
    "    return results, y_test_exp\n",
    "\n",
    "print(\"ğŸ”¬ å¼€å§‹è¿‡æ‹Ÿåˆå®éªŒ...\")\n",
    "results, y_test_exp = overfit_experiment(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–è¿‡æ‹Ÿåˆå®éªŒç»“æœ\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "train_sizes = list(results.keys())\n",
    "colors = plt.cm.viridis(np.linspace(0, 0.8, len(train_sizes)))\n",
    "\n",
    "# ä¸Šæ’ï¼šæŸå¤±æ›²çº¿å¯¹æ¯”\n",
    "for idx, (train_size, color) in enumerate(zip(train_sizes, colors)):\n",
    "    if idx < 3:\n",
    "        ax = axes[0, idx]\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    ax.plot(results[train_size]['train_losses'], 'b-', label='Train', linewidth=2)\n",
    "    ax.plot(results[train_size]['test_losses'], 'r-', label='Test', linewidth=2)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title(f'è®­ç»ƒæ•°æ®: {train_size} å¤©', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "# ä¸‹æ’ï¼šé¢„æµ‹å¯¹æ¯”\n",
    "axes[1, 0].plot(y_test_exp[:100], 'k-', linewidth=2, label='Observed')\n",
    "for train_size, color in zip(train_sizes[:3], colors[:3]):\n",
    "    axes[1, 0].plot(results[train_size]['predictions'][:100], \n",
    "                   color=color, alpha=0.7, label=f'{train_size} days')\n",
    "axes[1, 0].set_xlabel('Test Sample Index')\n",
    "axes[1, 0].set_ylabel('Discharge [mm/day]')\n",
    "axes[1, 0].set_title('ä¸åŒæ•°æ®é‡çš„é¢„æµ‹æ•ˆæœ', fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# å­¦ä¹ æ›²çº¿\n",
    "final_train_losses = [results[s]['train_losses'][-1] for s in train_sizes]\n",
    "final_test_losses = [results[s]['test_losses'][-1] for s in train_sizes]\n",
    "\n",
    "axes[1, 1].plot(train_sizes, final_train_losses, 'bo-', markersize=10, label='Train Loss')\n",
    "axes[1, 1].plot(train_sizes, final_test_losses, 'ro-', markersize=10, label='Test Loss')\n",
    "axes[1, 1].fill_between(train_sizes, final_train_losses, final_test_losses, \n",
    "                        color='yellow', alpha=0.3, label='Overfit Gap')\n",
    "axes[1, 1].set_xlabel('Training Data Size [days]')\n",
    "axes[1, 1].set_ylabel('Final Loss')\n",
    "axes[1, 1].set_title('å­¦ä¹ æ›²çº¿ï¼šæ•°æ®é‡ vs æ€§èƒ½', fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# è¿‡æ‹Ÿåˆç¨‹åº¦\n",
    "overfit_ratio = [final_test_losses[i] / final_train_losses[i] for i in range(len(train_sizes))]\n",
    "axes[1, 2].bar(range(len(train_sizes)), overfit_ratio, color=colors)\n",
    "axes[1, 2].set_xticks(range(len(train_sizes)))\n",
    "axes[1, 2].set_xticklabels([str(s) for s in train_sizes])\n",
    "axes[1, 2].axhline(y=1, color='red', linestyle='--', label='No Overfit')\n",
    "axes[1, 2].set_xlabel('Training Data Size [days]')\n",
    "axes[1, 2].set_ylabel('Test/Train Loss Ratio')\n",
    "axes[1, 2].set_title('è¿‡æ‹Ÿåˆç¨‹åº¦', fontweight='bold')\n",
    "axes[1, 2].legend()\n",
    "\n",
    "plt.suptitle('è¿‡æ‹Ÿåˆå®éªŒï¼šæ•°æ®é‡å¯¹æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„å½±å“', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ å…³é”®å‘ç°\n",
    "\n",
    "1. **æ•°æ®å¤ªå°‘æ—¶**ï¼ˆå¦‚10å¤©ï¼‰ï¼š\n",
    "   - è®­ç»ƒæŸå¤±å¾ˆä½ï¼ˆæ¨¡å‹\"è®°ä½\"äº†æ‰€æœ‰è®­ç»ƒæ•°æ®ï¼‰\n",
    "   - æµ‹è¯•æŸå¤±å¾ˆé«˜ï¼ˆæ¨¡å‹åœ¨æ–°æ•°æ®ä¸Šè¡¨ç°å¾ˆå·®ï¼‰\n",
    "   - è¿™å°±æ˜¯**è¿‡æ‹Ÿåˆ (Overfitting)**ï¼\n",
    "\n",
    "2. **æ•°æ®é‡å¢åŠ æ—¶**ï¼š\n",
    "   - è®­ç»ƒæŸå¤±å’Œæµ‹è¯•æŸå¤±çš„å·®è·é€æ¸ç¼©å°\n",
    "   - æ¨¡å‹çš„**æ³›åŒ–èƒ½åŠ› (Generalization)** æé«˜\n",
    "\n",
    "3. **è¿™å°±æ˜¯ä¸ºä»€ä¹ˆ**ï¼š\n",
    "   - æ•°æ®é©±åŠ¨æ¨¡å‹éœ€è¦å¤§é‡æ•°æ®\n",
    "   - è®ºæ–‡ç ”ç©¶\"å­¦ä¹ æ›²çº¿\"å¾ˆé‡è¦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š æ€»ç»“\n",
    "\n",
    "### æ•°æ®é©±åŠ¨æ¨¡å‹ vs ç‰©ç†æ¨¡å‹\n",
    "\n",
    "| ç‰¹æ€§ | ç‰©ç†æ¨¡å‹ (HBV) | æ•°æ®é©±åŠ¨æ¨¡å‹ (LSTM) |\n",
    "|------|---------------|--------------------|\n",
    "| **å­¦ä¹ æ–¹å¼** | åŸºäºå…¬å¼ | ä»æ•°æ®ä¸­å­¦ä¹  |\n",
    "| **æ•°æ®éœ€æ±‚** | è¾ƒå°‘ | è¾ƒå¤š |\n",
    "| **å¯è§£é‡Šæ€§** | é«˜ï¼ˆå‚æ•°æœ‰ç‰©ç†æ„ä¹‰ï¼‰ | ä½ï¼ˆé»‘ç›’å­ï¼‰ |\n",
    "| **å¤–æ¨èƒ½åŠ›** | è¾ƒå¥½ | è¾ƒå·® |\n",
    "| **è®¡ç®—éœ€æ±‚** | ä½ | é«˜ï¼ˆGPUåŠ é€Ÿï¼‰ |\n",
    "| **ç²¾åº¦ä¸Šé™** | å—é™äºå…¬å¼ç®€åŒ– | å¯èƒ½æ›´é«˜ |\n",
    "\n",
    "### æœ¬æ¨¡å—å­¦åˆ°äº†ä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "1. **LSTMçš„å·¥ä½œåŸç†**ï¼šé€šè¿‡\"è®°å¿†\"æœºåˆ¶å­¦ä¹ æ—¶åºä¾èµ–\n",
    "2. **æ•°æ®å‡†å¤‡**ï¼šæ»‘åŠ¨çª—å£æ–¹æ³•\n",
    "3. **è®­ç»ƒè¿‡ç¨‹**ï¼šæŸå¤±ä¸‹é™ã€å‚æ•°ä¼˜åŒ–\n",
    "4. **è¿‡æ‹Ÿåˆé—®é¢˜**ï¼šæ•°æ®é‡çš„é‡è¦æ€§\n",
    "\n",
    "### ä¸‹ä¸€æ­¥å­¦ä¹ \n",
    "\n",
    "åœ¨ä¸‹ä¸€ä¸ªæ¨¡å—ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ å¦‚ä½•**è¯„ä¼°æ¨¡å‹**â€”â€”\n",
    "ä¸åŒçš„æŒ‡æ ‡ï¼ˆNSEã€KGEã€ä¿¡æ¯ç†µï¼‰å„æœ‰ä»€ä¹ˆä¼˜ç¼ºç‚¹ï¼Ÿ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
