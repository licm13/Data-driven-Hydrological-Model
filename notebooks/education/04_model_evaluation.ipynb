{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“˜ Module 4: è°çš„æ¨¡å‹æ›´å¥½ï¼Ÿ- æ¨¡å‹è¯„ä¼°è£åˆ¤ (The Judge)\n",
    "\n",
    "## å­¦ä¹ ç›®æ ‡ (Learning Objectives)\n",
    "\n",
    "- ç†è§£NSEã€KGEç­‰ä¼ ç»Ÿæ°´æ–‡è¯„ä¼°æŒ‡æ ‡\n",
    "- å­¦ä¹ ä¿¡æ¯è®ºæŒ‡æ ‡çš„å«ä¹‰å’Œåº”ç”¨\n",
    "- æŒæ¡å¤šç»´åº¦è¯„ä¼°æ¨¡å‹æ€§èƒ½çš„æ–¹æ³•\n",
    "- ç†è§£ä¸åŒæŒ‡æ ‡åœ¨ä¸åŒåœºæ™¯ä¸‹çš„é€‚ç”¨æ€§\n",
    "\n",
    "---\n",
    "\n",
    "## âš–ï¸ ä¸ºä»€ä¹ˆéœ€è¦è¯„ä¼°æŒ‡æ ‡ï¼Ÿ\n",
    "\n",
    "åœ¨å‰é¢çš„æ¨¡å—ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†ä¸åŒç±»å‹çš„æ°´æ–‡æ¨¡å‹ã€‚ä½†å¦‚ä½•åˆ¤æ–­å“ªä¸ªæ¨¡å‹æ›´å¥½ï¼Ÿ\n",
    "\n",
    "è¿™å°±éœ€è¦ä¸€ä¸ªå…¬æ­£çš„\"è£åˆ¤\"â€”â€”**è¯„ä¼°æŒ‡æ ‡ (Evaluation Metrics)**ã€‚\n",
    "\n",
    "### ä¸€ä¸ªæœ‰è¶£çš„é—®é¢˜ ğŸ¤”\n",
    "\n",
    "å‡è®¾æœ‰ä¸¤ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœï¼š\n",
    "- **æ¨¡å‹A**ï¼šå³°å€¼æ—¶é—´å‡†ç¡®ï¼Œä½†æ°´é‡æ€»æ˜¯åå¤š\n",
    "- **æ¨¡å‹B**ï¼šæ€»æ°´é‡å‡†ç¡®ï¼Œä½†å³°å€¼æ€»æ˜¯å»¶è¿Ÿ\n",
    "\n",
    "å“ªä¸ªæ¨¡å‹æ›´å¥½ï¼Ÿâ€”â€”è¿™å–å†³äºä½ çš„åº”ç”¨åœºæ™¯ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®è·¯å¾„\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# è®¾ç½®ç»˜å›¾å‚æ•°\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒè®¾ç½®å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Part 1: å‡†å¤‡æ¼”ç¤ºæ•°æ®\n",
    "\n",
    "é¦–å…ˆï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€äº›æ¨¡æ‹Ÿåœºæ™¯æ¥ç†è§£ä¸åŒè¯„ä¼°æŒ‡æ ‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_evaluation_scenarios(n=200):\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆä¸åŒç‰¹å¾çš„æ¨¡å‹é¢„æµ‹ç»“æœç”¨äºæ¼”ç¤º\n",
    "    \"\"\"\n",
    "    # åˆ›å»º\"çœŸå®\"è§‚æµ‹å€¼\n",
    "    t = np.arange(n)\n",
    "    # åŸºç¡€æµé‡ + å‡ æ¬¡æ´ªæ°´äº‹ä»¶\n",
    "    observed = 10 + 5 * np.sin(t / 20)  # åŸºæµå˜åŒ–\n",
    "    \n",
    "    # æ·»åŠ æ´ªæ°´äº‹ä»¶\n",
    "    flood_peaks = [30, 80, 130, 170]\n",
    "    for peak in flood_peaks:\n",
    "        observed += 50 * np.exp(-0.1 * np.abs(t - peak))\n",
    "    \n",
    "    observed += np.random.normal(0, 1, n)  # å™ªå£°\n",
    "    observed = np.maximum(0, observed)\n",
    "    \n",
    "    # åˆ›å»ºä¸åŒç‰¹å¾çš„æ¨¡å‹é¢„æµ‹\n",
    "    predictions = {}\n",
    "    \n",
    "    # æ¨¡å‹A: å®Œç¾æ¨¡å‹ï¼ˆç•¥å¾®åŠ å™ªå£°ï¼‰\n",
    "    predictions['Perfect'] = observed + np.random.normal(0, 0.5, n)\n",
    "    \n",
    "    # æ¨¡å‹B: å³°å€¼å‡†ç¡®ä½†åä½\n",
    "    predictions['Low Bias'] = observed * 0.8 + np.random.normal(0, 1, n)\n",
    "    \n",
    "    # æ¨¡å‹C: æ—¶é—´å»¶è¿Ÿ\n",
    "    predictions['Time Lag'] = np.roll(observed, 3) + np.random.normal(0, 1, n)\n",
    "    \n",
    "    # æ¨¡å‹D: é«˜å˜å¼‚æ€§ï¼ˆè¿‡äºæ•æ„Ÿï¼‰\n",
    "    predictions['High Var'] = observed + observed * 0.3 * np.random.randn(n)\n",
    "    \n",
    "    # æ¨¡å‹E: å¹³æ»‘ï¼ˆä¸æ•æ„Ÿï¼‰\n",
    "    from scipy.ndimage import uniform_filter1d\n",
    "    predictions['Smoothed'] = uniform_filter1d(observed, size=10)\n",
    "    \n",
    "    # æ¨¡å‹F: åªé¢„æµ‹å‡å€¼ï¼ˆæœ€å·®æ¨¡å‹ï¼‰\n",
    "    predictions['Mean Only'] = np.full(n, np.mean(observed))\n",
    "    \n",
    "    return observed, predictions\n",
    "\n",
    "# ç”Ÿæˆæ•°æ®\n",
    "observed, predictions = generate_evaluation_scenarios(200)\n",
    "print(f\"ğŸ“Š ç”Ÿæˆäº† 6 ç§ä¸åŒç‰¹å¾çš„æ¨¡å‹é¢„æµ‹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ä¸åŒæ¨¡å‹çš„é¢„æµ‹æ•ˆæœ\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 12), sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "colors = plt.cm.Set1(np.linspace(0, 1, 6))\n",
    "\n",
    "for idx, (name, pred) in enumerate(predictions.items()):\n",
    "    ax = axes[idx]\n",
    "    ax.plot(observed, 'k-', linewidth=2, alpha=0.5, label='Observed')\n",
    "    ax.plot(pred, '-', color=colors[idx], linewidth=1.5, label=f'{name}')\n",
    "    ax.set_title(f'Model: {name}', fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_ylabel('Discharge [mm/day]')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "axes[4].set_xlabel('Time [days]')\n",
    "axes[5].set_xlabel('Time [days]')\n",
    "\n",
    "plt.suptitle('ä¸åŒæ¨¡å‹é¢„æµ‹ç‰¹å¾å¯¹æ¯”', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Part 2: Nash-Sutcliffeæ•ˆç‡ç³»æ•° (NSE)\n",
    "\n",
    "### å…¬å¼\n",
    "\n",
    "$$NSE = 1 - \\frac{\\sum_{t=1}^{n}(Q_{obs}^t - Q_{sim}^t)^2}{\\sum_{t=1}^{n}(Q_{obs}^t - \\overline{Q_{obs}})^2}$$\n",
    "\n",
    "### è§£é‡Š\n",
    "- **NSE = 1**ï¼šå®Œç¾é¢„æµ‹\n",
    "- **NSE = 0**ï¼šæ¨¡å‹å’Œè§‚æµ‹å‡å€¼ä¸€æ ·å¥½\n",
    "- **NSE < 0**ï¼šæ¨¡å‹æ¯”ä½¿ç”¨å‡å€¼è¿˜å·®\n",
    "\n",
    "### ç‰¹ç‚¹\n",
    "- å¯¹**æ´ªå³°**éå¸¸æ•æ„Ÿï¼ˆå› ä¸ºå¹³æ–¹é¡¹æ”¾å¤§äº†å¤§è¯¯å·®ï¼‰\n",
    "- æ˜¯æ°´æ–‡å­¦æœ€å¸¸ç”¨çš„æŒ‡æ ‡ä¹‹ä¸€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nse(observed, simulated):\n",
    "    \"\"\"\n",
    "    è®¡ç®—Nash-Sutcliffeæ•ˆç‡ç³»æ•°\n",
    "    \"\"\"\n",
    "    numerator = np.sum((observed - simulated) ** 2)\n",
    "    denominator = np.sum((observed - np.mean(observed)) ** 2)\n",
    "    return 1 - numerator / (denominator + 1e-10)\n",
    "\n",
    "# è®¡ç®—æ‰€æœ‰æ¨¡å‹çš„NSE\n",
    "print(\"ğŸ“Š NSE (Nash-Sutcliffe Efficiency) è¯„åˆ†:\\n\")\n",
    "print(f\"{'Model':<15} {'NSE':>10} {'Interpretation':<30}\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "nse_scores = {}\n",
    "for name, pred in predictions.items():\n",
    "    score = nse(observed, pred)\n",
    "    nse_scores[name] = score\n",
    "    \n",
    "    if score > 0.9:\n",
    "        interp = \"Excellent (ä¼˜ç§€)\"\n",
    "    elif score > 0.7:\n",
    "        interp = \"Good (è‰¯å¥½)\"\n",
    "    elif score > 0.5:\n",
    "        interp = \"Satisfactory (åŠæ ¼)\"\n",
    "    elif score > 0:\n",
    "        interp = \"Unsatisfactory (ä¸åŠæ ¼)\"\n",
    "    else:\n",
    "        interp = \"Poor - Worse than mean (å¾ˆå·®)\"\n",
    "    \n",
    "    print(f\"{name:<15} {score:>10.4f} {interp:<30}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Part 3: Kling-Guptaæ•ˆç‡ç³»æ•° (KGE)\n",
    "\n",
    "### å…¬å¼\n",
    "\n",
    "$$KGE = 1 - \\sqrt{(r-1)^2 + (\\alpha-1)^2 + (\\beta-1)^2}$$\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "- **r**ï¼šç›¸å…³ç³»æ•°ï¼ˆæ—¶é—´åŒæ­¥æ€§ï¼‰\n",
    "- **Î± = Ïƒ_sim / Ïƒ_obs**ï¼šå˜å¼‚æ€§æ¯”ï¼ˆæ³¢åŠ¨å¹…åº¦ï¼‰\n",
    "- **Î² = Î¼_sim / Î¼_obs**ï¼šåå·®æ¯”ï¼ˆæ€»é‡å‡†ç¡®æ€§ï¼‰\n",
    "\n",
    "### ä¼˜åŠ¿\n",
    "- åˆ†è§£ä¸ºä¸‰ä¸ªå¯è§£é‡Šçš„ç»„æˆéƒ¨åˆ†\n",
    "- æ›´å¹³è¡¡åœ°è€ƒè™‘ä¸åŒè¯¯å·®æ¥æº\n",
    "- æ¯”NSEæ›´é€‚åˆè¯Šæ–­é—®é¢˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kge(observed, simulated):\n",
    "    \"\"\"\n",
    "    è®¡ç®—Kling-Guptaæ•ˆç‡ç³»æ•°åŠå…¶ç»„æˆéƒ¨åˆ†\n",
    "    \"\"\"\n",
    "    # ç›¸å…³ç³»æ•°\n",
    "    r = np.corrcoef(observed, simulated)[0, 1]\n",
    "    \n",
    "    # å˜å¼‚æ€§æ¯”\n",
    "    alpha = np.std(simulated) / (np.std(observed) + 1e-10)\n",
    "    \n",
    "    # åå·®æ¯”\n",
    "    beta = np.mean(simulated) / (np.mean(observed) + 1e-10)\n",
    "    \n",
    "    # KGE\n",
    "    kge_value = 1 - np.sqrt((r - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)\n",
    "    \n",
    "    return kge_value, r, alpha, beta\n",
    "\n",
    "# è®¡ç®—æ‰€æœ‰æ¨¡å‹çš„KGE\n",
    "print(\"ğŸ“Š KGE (Kling-Gupta Efficiency) è¯„åˆ†:\\n\")\n",
    "print(f\"{'Model':<15} {'KGE':>8} {'r':>8} {'Î±':>8} {'Î²':>8}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "kge_results = {}\n",
    "for name, pred in predictions.items():\n",
    "    kge_val, r, alpha, beta = kge(observed, pred)\n",
    "    kge_results[name] = {'KGE': kge_val, 'r': r, 'alpha': alpha, 'beta': beta}\n",
    "    print(f\"{name:<15} {kge_val:>8.4f} {r:>8.4f} {alpha:>8.4f} {beta:>8.4f}\")\n",
    "\n",
    "print(\"\\nğŸ“– è§£è¯»ï¼š\")\n",
    "print(\"  r = ç›¸å…³æ€§ (1 = å®Œç¾åŒæ­¥)\")\n",
    "print(\"  Î± = å˜å¼‚æ€§æ¯” (1 = æ³¢åŠ¨å¹…åº¦ä¸€è‡´)\")\n",
    "print(\"  Î² = åå·®æ¯” (1 = æ€»é‡å‡†ç¡®)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–KGEåˆ†è§£\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 5))\n",
    "\n",
    "model_names = list(kge_results.keys())\n",
    "x_pos = np.arange(len(model_names))\n",
    "colors_bar = plt.cm.Set2(np.linspace(0, 1, len(model_names)))\n",
    "\n",
    "# r å€¼\n",
    "r_values = [kge_results[m]['r'] for m in model_names]\n",
    "axes[0].bar(x_pos, r_values, color=colors_bar)\n",
    "axes[0].axhline(y=1, color='red', linestyle='--', label='Optimal=1')\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(model_names, rotation=45, ha='right')\n",
    "axes[0].set_ylabel('Correlation (r)')\n",
    "axes[0].set_title('ç›¸å…³æ€§ï¼šæ—¶é—´åŒæ­¥æ€§', fontweight='bold')\n",
    "axes[0].legend()\n",
    "\n",
    "# Î± å€¼\n",
    "alpha_values = [kge_results[m]['alpha'] for m in model_names]\n",
    "axes[1].bar(x_pos, alpha_values, color=colors_bar)\n",
    "axes[1].axhline(y=1, color='red', linestyle='--', label='Optimal=1')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(model_names, rotation=45, ha='right')\n",
    "axes[1].set_ylabel('Variability Ratio (Î±)')\n",
    "axes[1].set_title('å˜å¼‚æ€§æ¯”ï¼šæ³¢åŠ¨å¹…åº¦', fontweight='bold')\n",
    "axes[1].legend()\n",
    "\n",
    "# Î² å€¼\n",
    "beta_values = [kge_results[m]['beta'] for m in model_names]\n",
    "axes[2].bar(x_pos, beta_values, color=colors_bar)\n",
    "axes[2].axhline(y=1, color='red', linestyle='--', label='Optimal=1')\n",
    "axes[2].set_xticks(x_pos)\n",
    "axes[2].set_xticklabels(model_names, rotation=45, ha='right')\n",
    "axes[2].set_ylabel('Bias Ratio (Î²)')\n",
    "axes[2].set_title('åå·®æ¯”ï¼šæ€»é‡å‡†ç¡®æ€§', fontweight='bold')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.suptitle('KGEç»„æˆéƒ¨åˆ†åˆ†è§£', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ è¯Šæ–­åˆ†æ\n",
    "\n",
    "ä»KGEåˆ†è§£ä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼š\n",
    "\n",
    "- **Low Biasæ¨¡å‹**ï¼šÎ²=0.8 â†’ ç³»ç»Ÿæ€§ä½ä¼°ï¼ˆæ€»é‡åå°‘ï¼‰\n",
    "- **Time Lagæ¨¡å‹**ï¼šrè¾ƒä½ â†’ æ—¶é—´ä¸åŒæ­¥\n",
    "- **Smoothedæ¨¡å‹**ï¼šÎ±<1 â†’ å˜å¼‚æ€§ä¸è¶³ï¼ˆå¤ªå¹³æ»‘ï¼‰\n",
    "- **High Varæ¨¡å‹**ï¼šÎ±>1 â†’ å˜å¼‚æ€§è¿‡å¤§ï¼ˆå¤ªæ•æ„Ÿï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§® Part 4: ä¿¡æ¯è®ºæŒ‡æ ‡\n",
    "\n",
    "é™¤äº†ä¼ ç»ŸæŒ‡æ ‡ï¼Œä¿¡æ¯è®ºæä¾›äº†å¦ä¸€ä¸ªè§†è§’æ¥è¯„ä¼°æ¨¡å‹ã€‚\n",
    "\n",
    "### æ¡ä»¶ç†µ H(Obs|Sim)\n",
    "\n",
    "**å«ä¹‰**ï¼šç»™å®šæ¨¡å‹é¢„æµ‹åï¼Œè§‚æµ‹å€¼è¿˜æœ‰å¤šå°‘ä¸ç¡®å®šæ€§ï¼Ÿ\n",
    "\n",
    "- **H = 0**ï¼šå®Œç¾é¢„æµ‹ï¼ˆæ²¡æœ‰å‰©ä½™ä¸ç¡®å®šæ€§ï¼‰\n",
    "- **H è¶Šå¤§**ï¼šæ¨¡å‹æä¾›çš„ä¿¡æ¯è¶Šå°‘\n",
    "\n",
    "### å½’ä¸€åŒ–æ¡ä»¶ç†µ\n",
    "\n",
    "$$H_{norm} = \\frac{H(Obs|Sim)}{H(Obs)}$$\n",
    "\n",
    "- **èŒƒå›´ [0, 1]**\n",
    "- **0 = å®Œç¾**\n",
    "- **1 = æ¨¡å‹æ²¡æœ‰æä¾›ä»»ä½•ä¿¡æ¯**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥é¡¹ç›®ä¸­çš„ç†µè®¡ç®—å‡½æ•°\n",
    "try:\n",
    "    from src.metrics.entropy import (\n",
    "        conditional_entropy, \n",
    "        normalized_conditional_entropy,\n",
    "        mutual_information,\n",
    "        joint_entropy\n",
    "    )\n",
    "    print(\"âœ… æˆåŠŸå¯¼å…¥é¡¹ç›®ä¸­çš„ç†µè®¡ç®—æ¨¡å—\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ æ— æ³•å¯¼å…¥é¡¹ç›®æ¨¡å—ï¼Œä½¿ç”¨å†…ç½®å®ç°\")\n",
    "    \n",
    "    # ç®€åŒ–ç‰ˆå®ç°\n",
    "    def simple_entropy(data, n_bins=12):\n",
    "        \"\"\"è®¡ç®—ç®€å•ç†µ\"\"\"\n",
    "        counts, _ = np.histogram(data, bins=n_bins)\n",
    "        probs = counts / len(data)\n",
    "        probs = probs[probs > 0]\n",
    "        return -np.sum(probs * np.log2(probs))\n",
    "    \n",
    "    def conditional_entropy(obs, sim, n_bins=12):\n",
    "        \"\"\"è®¡ç®—æ¡ä»¶ç†µ H(obs|sim)\"\"\"\n",
    "        # è”åˆç†µ\n",
    "        joint_hist, _, _ = np.histogram2d(obs, sim, bins=n_bins)\n",
    "        joint_probs = joint_hist / len(obs)\n",
    "        joint_probs = joint_probs[joint_probs > 0]\n",
    "        H_joint = -np.sum(joint_probs * np.log2(joint_probs))\n",
    "        \n",
    "        # simçš„è¾¹é™…ç†µ\n",
    "        H_sim = simple_entropy(sim, n_bins)\n",
    "        \n",
    "        return H_joint - H_sim\n",
    "    \n",
    "    def normalized_conditional_entropy(obs, sim, n_bins=12):\n",
    "        \"\"\"è®¡ç®—å½’ä¸€åŒ–æ¡ä»¶ç†µ\"\"\"\n",
    "        H_cond = conditional_entropy(obs, sim, n_bins)\n",
    "        H_obs = simple_entropy(obs, n_bins)\n",
    "        return H_cond / (H_obs + 1e-10)\n",
    "    \n",
    "    def mutual_information(obs, sim, n_bins=12):\n",
    "        \"\"\"è®¡ç®—äº’ä¿¡æ¯\"\"\"\n",
    "        H_obs = simple_entropy(obs, n_bins)\n",
    "        H_cond = conditional_entropy(obs, sim, n_bins)\n",
    "        return H_obs - H_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¡ç®—ä¿¡æ¯è®ºæŒ‡æ ‡\n",
    "print(\"ğŸ“Š ä¿¡æ¯è®ºæŒ‡æ ‡è¯„åˆ†:\\n\")\n",
    "print(f\"{'Model':<15} {'H_cond':>10} {'H_norm':>10} {'MI':>10}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "entropy_results = {}\n",
    "for name, pred in predictions.items():\n",
    "    h_cond = conditional_entropy(observed, pred)\n",
    "    h_norm = normalized_conditional_entropy(observed, pred)\n",
    "    mi = mutual_information(observed, pred)\n",
    "    \n",
    "    entropy_results[name] = {'H_cond': h_cond, 'H_norm': h_norm, 'MI': mi}\n",
    "    print(f\"{name:<15} {h_cond:>10.4f} {h_norm:>10.4f} {mi:>10.4f}\")\n",
    "\n",
    "print(\"\\nğŸ“– è§£è¯»ï¼š\")\n",
    "print(\"  H_cond = æ¡ä»¶ç†µ (è¶Šä½è¶Šå¥½)\")\n",
    "print(\"  H_norm = å½’ä¸€åŒ–æ¡ä»¶ç†µ (0=å®Œç¾, 1=æ— ä¿¡æ¯)\")\n",
    "print(\"  MI = äº’ä¿¡æ¯ (è¶Šé«˜è¶Šå¥½ï¼Œè¡¨ç¤ºå…±äº«ä¿¡æ¯é‡)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Part 5: ç›´è§‰é™·é˜±å®éªŒ\n",
    "\n",
    "ç°åœ¨è®©æˆ‘ä»¬åšä¸€ä¸ªå®éªŒï¼šçœ‹çœ‹ç›´è§‰åˆ¤æ–­å’Œé‡åŒ–è¯„ä¼°æ˜¯å¦ä¸€è‡´ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºä¸¤ä¸ªç‰¹æ®Šåœºæ™¯\n",
    "n = 100\n",
    "t = np.arange(n)\n",
    "\n",
    "# çœŸå®è§‚æµ‹å€¼\n",
    "obs_special = 20 + 30 * np.exp(-0.05 * np.abs(t - 50))  # ä¸€æ¬¡æ´ªå³°\n",
    "obs_special += np.random.normal(0, 1, n)\n",
    "\n",
    "# æ¨¡å‹A: å³°å€¼å‡†ç¡®ä½†æ°´é‡åå¤š\n",
    "pred_A = obs_special * 1.2  # æ°´é‡åå¤š20%\n",
    "\n",
    "# æ¨¡å‹B: æ°´é‡å‡†ç¡®ä½†å³°å€¼å»¶è¿Ÿ\n",
    "pred_B = np.roll(obs_special, 5)  # å»¶è¿Ÿ5å¤©\n",
    "pred_B[:5] = obs_special[:5]  # å¤„ç†è¾¹ç•Œ\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].fill_between(t, 0, obs_special, alpha=0.3, color='black', label='Observed')\n",
    "axes[0].plot(obs_special, 'k-', linewidth=2)\n",
    "axes[0].plot(pred_A, 'r-', linewidth=2, label='Model A: Peak aligned, volume +20%')\n",
    "axes[0].set_xlabel('Time [days]')\n",
    "axes[0].set_ylabel('Discharge [mm/day]')\n",
    "axes[0].set_title('æ¨¡å‹A: å³°å€¼å‡†ç¡®ï¼Œæ°´é‡åå¤š', fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].fill_between(t, 0, obs_special, alpha=0.3, color='black', label='Observed')\n",
    "axes[1].plot(obs_special, 'k-', linewidth=2)\n",
    "axes[1].plot(pred_B, 'b-', linewidth=2, label='Model B: Volume OK, peak delayed')\n",
    "axes[1].set_xlabel('Time [days]')\n",
    "axes[1].set_ylabel('Discharge [mm/day]')\n",
    "axes[1].set_title('æ¨¡å‹B: æ°´é‡å‡†ç¡®ï¼Œå³°å€¼å»¶è¿Ÿ', fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('ğŸ¤” æŠ•ç¥¨ï¼šå“ªä¸ªæ¨¡å‹æ›´å¥½ï¼Ÿ', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¡ç®—ä¸¤ä¸ªæ¨¡å‹çš„æ‰€æœ‰æŒ‡æ ‡\n",
    "print(\"\\nğŸ“Š æ¨¡å‹A vs æ¨¡å‹B è¯„ä¼°å¯¹æ¯”:\\n\")\n",
    "\n",
    "results_compare = pd.DataFrame(index=['Model A (Volume+)', 'Model B (Time Lag)'])\n",
    "\n",
    "# NSE\n",
    "results_compare['NSE'] = [nse(obs_special, pred_A), nse(obs_special, pred_B)]\n",
    "\n",
    "# KGE\n",
    "kge_A, r_A, alpha_A, beta_A = kge(obs_special, pred_A)\n",
    "kge_B, r_B, alpha_B, beta_B = kge(obs_special, pred_B)\n",
    "results_compare['KGE'] = [kge_A, kge_B]\n",
    "results_compare['r'] = [r_A, r_B]\n",
    "results_compare['Î±'] = [alpha_A, alpha_B]\n",
    "results_compare['Î²'] = [beta_A, beta_B]\n",
    "\n",
    "# ç†µæŒ‡æ ‡\n",
    "results_compare['H_norm'] = [\n",
    "    normalized_conditional_entropy(obs_special, pred_A),\n",
    "    normalized_conditional_entropy(obs_special, pred_B)\n",
    "]\n",
    "\n",
    "# æ€»æ°´é‡è¯¯å·®\n",
    "results_compare['Volume Error %'] = [\n",
    "    (np.sum(pred_A) - np.sum(obs_special)) / np.sum(obs_special) * 100,\n",
    "    (np.sum(pred_B) - np.sum(obs_special)) / np.sum(obs_special) * 100\n",
    "]\n",
    "\n",
    "print(results_compare.round(4).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ’¡ åˆ†æç»“è®ºï¼š\")\n",
    "print(\"=\"*60)\n",
    "if results_compare.loc['Model A (Volume+)', 'NSE'] > results_compare.loc['Model B (Time Lag)', 'NSE']:\n",
    "    print(f\"NSEæ›´åçˆ±: æ¨¡å‹A (å› ä¸ºNSEå¯¹æ—¶é—´ä¸åŒæ­¥æƒ©ç½šæ›´å¤§)\")\n",
    "else:\n",
    "    print(f\"NSEæ›´åçˆ±: æ¨¡å‹B\")\n",
    "    \n",
    "print(f\"\\næ¨¡å‹Aé—®é¢˜: Î²={beta_A:.3f} (åç¦»1ï¼Œæ°´é‡ä¸å‡†)\")\n",
    "print(f\"æ¨¡å‹Bé—®é¢˜: r={r_B:.3f} (ç›¸å…³æ€§é™ä½ï¼Œæ—¶é—´ä¸åŒæ­¥)\")\n",
    "print(\"\\nğŸ‘‰ ç»“è®ºï¼šæ²¡æœ‰'æœ€å¥½'çš„æŒ‡æ ‡ï¼Œé€‰æ‹©å–å†³äºåº”ç”¨åœºæ™¯ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Part 6: é›·è¾¾å›¾å¤šç»´è¯„ä¼°\n",
    "\n",
    "åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬åº”è¯¥ç»¼åˆå¤šä¸ªæŒ‡æ ‡æ¥è¯„ä¼°æ¨¡å‹ã€‚é›·è¾¾å›¾æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å¯è§†åŒ–æ–¹å¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_radar_chart(model_scores, title=\"æ¨¡å‹å¤šç»´è¯„ä¼°é›·è¾¾å›¾\"):\n",
    "    \"\"\"\n",
    "    åˆ›å»ºé›·è¾¾å›¾æ¯”è¾ƒå¤šä¸ªæ¨¡å‹\n",
    "    \n",
    "    model_scores: dict, {model_name: {metric_name: score}}\n",
    "    \"\"\"\n",
    "    from matplotlib.patches import Patch\n",
    "    \n",
    "    # æŒ‡æ ‡åç§°ï¼ˆè½¬æ¢ä¸º0-1èŒƒå›´ï¼Œè¶Šå¤§è¶Šå¥½ï¼‰\n",
    "    metrics = ['NSE', 'KGE', 'Correlation', 'Volume Acc.', 'Info. Content']\n",
    "    \n",
    "    # è®¡ç®—æ¯ä¸ªæ¨¡å‹çš„å¾—åˆ†\n",
    "    model_data = {}\n",
    "    for name, pred in predictions.items():\n",
    "        nse_score = max(0, nse(observed, pred))  # æˆªæ–­è´Ÿå€¼\n",
    "        kge_score, r, alpha, beta = kge(observed, pred)\n",
    "        kge_score = max(0, kge_score)\n",
    "        h_norm = normalized_conditional_entropy(observed, pred)\n",
    "        info_content = max(0, 1 - h_norm)  # è½¬æ¢ä¸º\"è¶Šå¤§è¶Šå¥½\"\n",
    "        volume_acc = 1 - abs(beta - 1)  # æ°´é‡å‡†ç¡®æ€§\n",
    "        \n",
    "        model_data[name] = [nse_score, kge_score, r, volume_acc, info_content]\n",
    "    \n",
    "    # ç»˜åˆ¶é›·è¾¾å›¾\n",
    "    n_metrics = len(metrics)\n",
    "    angles = np.linspace(0, 2 * np.pi, n_metrics, endpoint=False).tolist()\n",
    "    angles += angles[:1]  # é—­åˆ\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
    "    \n",
    "    colors = plt.cm.Set1(np.linspace(0, 1, len(model_data)))\n",
    "    \n",
    "    for (name, scores), color in zip(model_data.items(), colors):\n",
    "        values = scores + scores[:1]  # é—­åˆ\n",
    "        ax.plot(angles, values, 'o-', linewidth=2, label=name, color=color)\n",
    "        ax.fill(angles, values, alpha=0.1, color=color)\n",
    "    \n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(metrics, size=12)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(title, size=14, fontweight='bold', y=1.08)\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "    ax.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "create_radar_chart(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š æ€»ç»“\n",
    "\n",
    "### è¯„ä¼°æŒ‡æ ‡å¯¹æ¯”è¡¨\n",
    "\n",
    "| æŒ‡æ ‡ | èŒƒå›´ | æœ€ä¼˜å€¼ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |\n",
    "|------|------|--------|------|------|----------|\n",
    "| **NSE** | (-âˆ, 1] | 1 | å¹¿æ³›ä½¿ç”¨ï¼Œæ˜“ç†è§£ | å¯¹æ´ªå³°è¿‡äºæ•æ„Ÿ | ä¸€èˆ¬æ°´æ–‡æ¨¡æ‹Ÿ |\n",
    "| **KGE** | (-âˆ, 1] | 1 | å¯åˆ†è§£è¯Šæ–­ | è®¡ç®—ç¨å¤æ‚ | éœ€è¦è¯Šæ–­é—®é¢˜æ—¶ |\n",
    "| **H_norm** | [0, 1] | 0 | ç†è®ºåŸºç¡€å¼º | éœ€è¦ç¦»æ•£åŒ– | ä¿¡æ¯è®ºç ”ç©¶ |\n",
    "\n",
    "### é€‰æ‹©æŒ‡æ ‡çš„å»ºè®®\n",
    "\n",
    "1. **æ´ªæ°´é¢„æŠ¥**ï¼šé‡è§†å³°å€¼ï¼Œç”¨NSEæˆ–ä¸“é—¨çš„å³°å€¼æŒ‡æ ‡\n",
    "2. **æ°´èµ„æºç®¡ç†**ï¼šé‡è§†æ€»é‡ï¼Œç”¨Î²æˆ–æ°´é‡è¯¯å·®\n",
    "3. **æ¨¡å‹è¯Šæ–­**ï¼šç”¨KGEåˆ†è§£æ‰¾é—®é¢˜\n",
    "4. **ç§‘å­¦ç ”ç©¶**ï¼šå¤šæŒ‡æ ‡ç»¼åˆè¯„ä¼°\n",
    "\n",
    "### æœ¬æ¨¡å—å­¦åˆ°äº†ä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "1. **NSEçš„è®¡ç®—å’Œè§£è¯»**\n",
    "2. **KGEçš„ä¼˜åŠ¿å’Œä¸‰ä¸ªç»„æˆéƒ¨åˆ†**\n",
    "3. **ä¿¡æ¯è®ºæŒ‡æ ‡çš„å«ä¹‰**\n",
    "4. **æ²¡æœ‰ä¸‡èƒ½çš„æŒ‡æ ‡ï¼Œè¦æ ¹æ®åœºæ™¯é€‰æ‹©**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ æ­å–œå®Œæˆæœ¬æ•™ç¨‹ï¼\n",
    "\n",
    "é€šè¿‡è¿™å››ä¸ªæ¨¡å—ï¼Œä½ å·²ç»å­¦ä¹ äº†ï¼š\n",
    "1. æ°´æ–‡å¾ªç¯çš„åŸºæœ¬åŸç†å’Œç®€å•æ¨¡å‹\n",
    "2. ç‰©ç†æ¨¡å‹ï¼ˆHBVï¼‰çš„ç»“æ„å’Œå‚æ•°\n",
    "3. æ•°æ®é©±åŠ¨æ¨¡å‹ï¼ˆLSTMï¼‰çš„å·¥ä½œåŸç†\n",
    "4. å¦‚ä½•ç§‘å­¦åœ°è¯„ä¼°æ¨¡å‹æ€§èƒ½\n",
    "\n",
    "ç°åœ¨ä½ å·²ç»å…·å¤‡äº†ç†è§£å’Œä½¿ç”¨æœ¬é¡¹ç›®ä»£ç çš„åŸºç¡€çŸ¥è¯†ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
