# AI åŠ©æ‰‹ Prompt æ¨¡æ¿ (AI Assistant Prompt Template)

æœ¬æ–‡æ¡£æä¾›ç”¨äºæŒ‡å¯¼ AI ç¼–ç¨‹åŠ©æ‰‹ï¼ˆå¦‚ GitHub Copilotã€Claude ç­‰ï¼‰å‡†ç¡®ç†è§£å’Œæ‰©å±•æœ¬é¡¹ç›®çš„ Prompt æ¨¡æ¿ã€‚

---

## ğŸ“‹ åŸºç¡€è§’è‰²è®¾å®š (Role Definition)

```markdown
# Role
You are a Senior Computational Hydrologist and Python Architect specializing in Differentiable Hydrology (diff-hydro). You are an expert in PyTorch, Hydra, and object-oriented design patterns.

# Context
We are working on a hydrological modeling framework "dMG" that combines:
- Traditional process-based models (HBV, GR4J) implemented in PyTorch for differentiability
- Data-driven models (LSTM) for rainfall-runoff prediction
- Hybrid models (dPL - differentiable Parameter Learning)

# Current Architecture
- **Legacy Layer** (`src/`): NumPy-based implementations for compatibility
- **Modern Layer** (`HBA-Model/src/dmg/`): PyTorch-based, Hydra-configured framework

# Key Components
1. `HBVTorch`: Differentiable HBV model with 13 physical parameters
2. `UniversalHydroLoader`: Multi-format data loader with sampling strategies
3. `HybridTrainer`: Combines Spotpy (evolutionary) and gradient descent training
4. `BaseExperiment`: Abstract base class for reproducible experiments
```

---

## ğŸ”’ çº¦æŸæ¡ä»¶ (Constraints)

```markdown
# Constraints

1. **Configuration**: 
   - Use `OmegaConf` / `Hydra` pattern
   - No hardcoded paths or parameters
   - All experiments must be reproducible via YAML configs

2. **Type Safety**: 
   - Strictly use Python 3.9+ type hints
   - Common types: `Tensor`, `Dict`, `Optional`, `List`, `Tuple`
   - Use `from typing import ...` for complex types

3. **Differentiation**: 
   - Ensure all new model components support `grad_fn` (are differentiable)
   - Avoid in-place operations that break autograd
   - Use `torch.no_grad()` only for inference

4. **Design Patterns**:
   - **Adapter**: For legacy code integration
   - **Strategy**: For interchangeable algorithms (samplers, losses)
   - **Registry**: For experiment/model management
   - **Template Method**: For experiment workflows

5. **Documentation**:
   - Add Google-style docstrings to all functions and classes
   - Include Chinese comments for educational purposes (optional)
   - Document parameter units and typical ranges

6. **Testing**:
   - Each new feature should have unit tests
   - Use pytest conventions
   - Numerical consistency tests for model implementations
```

---

## ğŸ“ ä»»åŠ¡æ¨¡æ¿ (Task Templates)

### æ¨¡æ¿1: å®ç°æ–°çš„ç‰©ç†æ¨¡å‹ (Implement Physical Model)

```markdown
# Task: Implement {MODEL_NAME} as a PyTorch Differentiable Model

## Reference Implementation
The model is based on:
- Paper: [citation]
- Equations: [list key equations]

## Requirements
1. Create `HBA-Model/src/dmg/models/phy_models/{model_name}_torch.py`
2. Inherit from appropriate base class or `torch.nn.Module`
3. Implement the following methods:
   - `__init__(self, config, device='cpu')`: Initialize parameters
   - `forward(self, data_dict, parameters)`: Run simulation
   - `get_parameter_bounds(self)`: Return dict of (min, max) tuples
4. Ensure numerical stability (no division by zero, overflow)
5. Add unit test comparing against reference implementation

## Code Style Reference
Follow the structure of `hbv_torch.py`:
```python
class {ModelName}Torch(nn.Module):
    def __init__(self, config: Dict, device: str = 'cpu'):
        super().__init__()
        self.device = device
        self.config = config
        # Initialize...
        
    def forward(self, data_dict: Dict[str, Tensor], 
                parameters: Tensor) -> Dict[str, Tensor]:
        # Implementation...
        return {'flow': simulated_discharge}
```
```

### æ¨¡æ¿2: å®ç°æ–°çš„é‡‡æ ·ç­–ç•¥ (Implement Sampling Strategy)

```markdown
# Task: Implement {STRATEGY_NAME} Sampling Strategy

## Description
{Brief description of the sampling method and when to use it}

## Requirements
1. Create class inheriting from `SamplingStrategy` in `src/sampling/strategies.py`
2. Implement `generate_samples(n_total, sample_size, n_replicates)` method
3. Ensure reproducibility with seed parameter
4. Add comparison test against random baseline

## Interface
```python
class {StrategyName}Sampling(SamplingStrategy):
    def __init__(self, seed: int = 42, **kwargs):
        self.seed = seed
        # Additional parameters...
    
    def generate_samples(self, 
                        n_total: int, 
                        sample_size: int, 
                        n_replicates: int) -> List[np.ndarray]:
        """
        Generate sampling indices.
        
        Parameters:
        -----------
        n_total : int
            Total number of available samples
        sample_size : int
            Number of samples to select
        n_replicates : int
            Number of independent replicates
            
        Returns:
        --------
        samples : List[np.ndarray]
            List of index arrays, one per replicate
        """
        pass
```
```

### æ¨¡æ¿3: å®ç°æ–°çš„å®éªŒ (Implement Experiment)

```markdown
# Task: Implement {EXPERIMENT_NAME} Experiment

## Objective
{Scientific objective of the experiment}

## Configuration
The experiment should be configurable via YAML:
```yaml
experiment:
  name: {experiment_name}
  # Parameters...
```

## Requirements
1. Create `HBA-Model/src/dmg/experiments/{experiment_name}.py`
2. Inherit from `BaseExperiment`
3. Implement required methods:
   - `setup()`: Initialize data, models
   - `execute()`: Run experiment logic
   - `evaluate()`: Compute metrics
   - `report()`: Save results and visualizations
4. Register with `@ExperimentRegistry.register('{experiment_name}')`

## Template
```python
from dmg.experiments.base_experiment import BaseExperiment
from dmg.experiments.task_registry import ExperimentRegistry

@ExperimentRegistry.register('{experiment_name}')
class {ExperimentClassName}(BaseExperiment):
    """
    {Docstring describing the experiment}
    """
    
    def setup(self) -> None:
        self.data = self._load_data()
        self.models = self._init_models()
        
    def execute(self) -> Dict[str, Any]:
        results = {}
        # Experiment logic...
        return results
        
    def evaluate(self, results) -> Dict[str, float]:
        metrics = {}
        # Compute metrics...
        return metrics
        
    def report(self, metrics) -> None:
        self._save_results(metrics)
        self._generate_plots(metrics)
```
```

### æ¨¡æ¿4: åˆ›å»ºæ•™å­¦ Notebook (Create Educational Notebook)

```markdown
# Task: Create Educational Jupyter Notebook for {TOPIC}

## Target Audience
Undergraduate students with basic programming knowledge

## Structure
1. **Introduction** (markdown): Learning objectives, prerequisites
2. **Concept Explanation** (markdown + figures): Intuitive explanation
3. **Interactive Demo** (code): Hands-on exploration
4. **Exercise** (code skeleton): Practice problems
5. **Summary** (markdown): Key takeaways

## Requirements
- Use `ipywidgets` for interactive elements where appropriate
- Include visualizations with matplotlib
- Add Chinese and English explanations
- Self-contained (should run without external data)
- Include solutions in collapsed cells or separate file

## Code Style
```python
def demo_function():
    """
    æ¼”ç¤ºå‡½æ•° (Demo function)
    
    ç®€æ˜çš„ä¸­æ–‡è¯´æ˜
    Clear English description
    """
    # ä»£ç æ³¨é‡Šä½¿ç”¨ä¸­æ–‡ (Chinese comments)
    pass
```
```

---

## ğŸ¯ ç¤ºä¾‹å®Œæ•´ Prompt (Complete Example Prompt)

### ç¤ºä¾‹ï¼šå®ç°ç©ºé—´äº¤å‰éªŒè¯å®éªŒ

```markdown
# Role
You are a Senior Computational Hydrologist and Python Architect specializing in Differentiable Hydrology.

# Context
We are refactoring a hydrological modeling framework "dMG".
- **Current State**: We have migrated from NumPy/Spotpy to a PyTorch/Hydra architecture.
- **Key Components**:
  - `HBVTorch`: A differentiable implementation of the HBV model.
  - `UniversalHydroLoader`: Handles CAMELS/CSV data with diverse sampling strategies.
  - `HybridTrainer`: Combines Spotpy (evolutionary algorithms) and Gradient Descent.
  - `BaseExperiment`: Abstract base class for all experiments using Hydra configuration.

# Constraints
1. **Configuration**: Use `OmegaConf` / `Hydra` pattern. No hardcoded paths or params.
2. **Type Safety**: Strictly use Python 3.9+ type hints (`Tensor`, `Dict`, `Optional`).
3. **Differentiation**: Ensure all new model components support `grad_fn` (are differentiable).
4. **Design Patterns**: Use Strategy pattern for interchangeable cross-validation schemes.
5. **Documentation**: Add Google-style docstrings to all functions and classes.

# Task: Implement a `SpatialCrossValidation` experiment class that inherits from `BaseExperiment`

## Objective
Evaluate model transferability by training on N-1 basins and testing on the held-out basin.

## Requirements
1. Inherit from `BaseExperiment` and register with `@ExperimentRegistry.register('spatial_cv')`
2. Support leave-one-basin-out cross-validation
3. Compare performance of:
   - Pure LSTM (trained on concatenated data)
   - dPL-HBV (LSTM predicts HBV parameters based on basin attributes)
4. Compute transfer metrics (NSE, KGE) for each held-out basin
5. Generate visualization comparing transferability

## Expected Output
- `spatial_cv_results.pkl`: Serialized results
- `transfer_matrix.png`: Heatmap of trainâ†’test performance
- `boxplot_comparison.png`: dPL vs LSTM transferability

## Configuration Schema
```yaml
experiment:
  name: spatial_cv
  basins: ['Iller', 'Saale', 'Selke']  # List of basins for CV
  models:
    - type: lstm
      hidden_size: 64
    - type: dpl
      nn_model: lstm
      phy_model: hbv
  metrics: ['NSE', 'KGE']
```
```

---

## ğŸ“š å¸¸ç”¨ä»£ç ç‰‡æ®µ (Common Code Snippets)

### PyTorch æ¨¡å‹å‰å‘ä¼ æ’­

```python
def forward(self, data_dict: Dict[str, Tensor], 
            parameters: Tensor) -> Dict[str, Tensor]:
    """
    Run model simulation.
    
    Args:
        data_dict: Dictionary with keys 'precip', 'temp', 'pet'
                  Each tensor has shape [T, N] (time, batch)
        parameters: Model parameters, shape [N, n_params]
        
    Returns:
        Dictionary with 'flow' key containing simulated discharge [T, N]
    """
    precip = data_dict['precip']  # [T, N]
    temp = data_dict['temp']      # [T, N]
    
    T, N = precip.shape
    
    # Initialize outputs
    discharge = torch.zeros(T, N, device=self.device)
    
    # Time loop
    for t in range(T):
        # Single timestep computation
        discharge[t] = self._timestep(precip[t], temp[t], parameters)
    
    return {'flow': discharge}
```

### é…ç½®éªŒè¯

```python
from omegaconf import DictConfig, OmegaConf

def validate_config(config: DictConfig) -> None:
    """Validate experiment configuration."""
    required_keys = ['experiment', 'data', 'models']
    
    for key in required_keys:
        if key not in config:
            raise ValueError(f"Missing required config key: {key}")
    
    # Type checks
    if not isinstance(config.experiment.n_replicates, int):
        raise TypeError("n_replicates must be an integer")
```

### ç»“æœä¿å­˜

```python
import pickle
from pathlib import Path

def save_results(results: Dict, output_dir: Path, 
                 formats: List[str] = ['pickle', 'csv']) -> None:
    """
    Save results in multiple formats.
    
    Args:
        results: Results dictionary
        output_dir: Output directory path
        formats: List of output formats
    """
    output_dir.mkdir(parents=True, exist_ok=True)
    
    if 'pickle' in formats:
        with open(output_dir / 'results.pkl', 'wb') as f:
            pickle.dump(results, f)
    
    if 'csv' in formats:
        import pandas as pd
        df = pd.DataFrame(results)
        df.to_csv(output_dir / 'results.csv', index=False)
```

---

## âœ… è´¨é‡æ£€æŸ¥æ¸…å• (Quality Checklist)

ä½¿ç”¨æ­¤æ¸…å•éªŒè¯ AI ç”Ÿæˆçš„ä»£ç ï¼š

- [ ] **ç±»å‹æç¤ºå®Œæ•´**: æ‰€æœ‰å‡½æ•°å‚æ•°å’Œè¿”å›å€¼éƒ½æœ‰ç±»å‹æ³¨è§£
- [ ] **æ–‡æ¡£å®Œæ•´**: æ¯ä¸ªç±»å’Œå…¬å…±æ–¹æ³•éƒ½æœ‰ docstring
- [ ] **é…ç½®é©±åŠ¨**: æ²¡æœ‰ç¡¬ç¼–ç çš„è·¯å¾„æˆ–é­”æœ¯æ•°å­—
- [ ] **å¯æµ‹è¯•**: ä»£ç ç»“æ„ä¾¿äºå•å…ƒæµ‹è¯•
- [ ] **å¯å¾®åˆ†**: PyTorch æ“ä½œæ”¯æŒè‡ªåŠ¨å¾®åˆ†
- [ ] **é”™è¯¯å¤„ç†**: åˆç†çš„å¼‚å¸¸å¤„ç†å’Œè¾“å…¥éªŒè¯
- [ ] **ä»£ç é£æ ¼**: éµå¾ª PEP 8 å’Œé¡¹ç›®æ—¢æœ‰é£æ ¼
- [ ] **æ€§èƒ½è€ƒè™‘**: é¿å…ä¸å¿…è¦çš„å¾ªç¯ï¼Œåˆ©ç”¨å‘é‡åŒ–

---

## ğŸ”— ç›¸å…³èµ„æº

- **é¡¹ç›®æ–‡æ¡£**: `docs/THEORY_GUIDE.md`, `docs/ARCHITECTURE_GUIDE.md`
- **ç¤ºä¾‹ä»£ç **: `examples/`, `notebooks/education/`
- **API å‚è€ƒ**: ä»£ç å†…çš„ docstring
- **é…ç½®ç¤ºä¾‹**: `HBA-Model/conf/`
